{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport torch\nimport torchvision\nfrom torchvision import transforms, datasets, models\nfrom torch.utils.data import Dataset, DataLoader, sampler\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.optim import lr_scheduler\nimport matplotlib.pyplot as plt\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch import optim\nfrom skimage import io, transform\nfrom timeit import default_timer as timer\n\nfrom PIL import Image\n\n%matplotlib inline ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/train.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dataset class\n\nclass ImageDataset(Dataset):\n    \n\n    def __init__(self, csv_file, root_dir, transform=None):\n        \"\"\"\n        Args:\n            csv_file (string): Path to the csv file with labels.\n            root_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        self.data_frame = pd.read_csv(csv_file)\n        self.root_dir = root_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data_frame)\n\n    def __getitem__(self, idx):\n        img_name = os.path.join(self.root_dir, self.data_frame['Id'][idx])         # getting path of image\n        image = Image.open(img_name).convert('RGB')                                # reading image and converting to rgb if it is grayscale\n        label = np.array(self.data_frame['Category'][idx])                         # reading label of the image\n        \n        if self.transform:            \n            image = self.transform(image)                                          # applying transforms, if any\n        \n        sample = (image, label)        \n        return sample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Image transformations\nimage_transforms = {\n    # Train uses data augmentation along with normalization.\n    'train':\n    transforms.Compose([\n        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n        transforms.RandomRotation(degrees = 25),\n        transforms.ColorJitter(),\n        transforms.RandomHorizontalFlip(),\n        #transforms.RandomVerticalFlip(),\n        transforms.CenterCrop(size=224),  # Image net standards\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])  # Imagenet standards\n    ]),\n    # Validation does not use augmentation but uses the same normalization.\n    'val':\n    transforms.Compose([\n        transforms.Resize(size=256),\n        transforms.CenterCrop(size=224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    # Test does not use augmentation but uses the same normalization.\n    'test':\n    transforms.Compose([\n        transforms.Resize(size=256),\n        transforms.CenterCrop(size=224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# making the datasets which will be passed to dataloader.\n\ntrainset = ImageDataset(csv_file = '../input/train.csv', root_dir = '../input/data/data/', transform=image_transforms['train'])\n#validset = ImageDataset(csv_file = '../input/train.csv', root_dir = '../input/data/data/', transform=image_transforms['val'])\ntestset = ImageDataset(csv_file = '../input/sample_sub.csv', root_dir = '../input/data/data/', transform=image_transforms['test'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_size = 0.20\n\n# obtain training indices that will be used for validation\nnum_train = len(trainset)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\nsplit = int(np.floor(valid_size * num_train))\ntrain_idx, valid_idx = indices[split:], indices[:split]\n\n# define samplers for obtaining training and validation batches\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data loader\ntrain_loader = torch.utils.data.DataLoader(trainset, batch_size=15, sampler = train_sampler, num_workers=0)\nvalid_loader = torch.utils.data.DataLoader(trainset, batch_size=15, sampler=valid_sampler, num_workers=0)\ntest_loader = torch.utils.data.DataLoader(testset, batch_size=15, shuffle=False, num_workers=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking training sample size and label\nfor i in range(len(trainset)):\n    sample = trainset[i]\n    print(i, sample[0].size(), \" | Label: \", sample[1])\n    if i == 10:\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the shape of each batch\ntrainiter = iter(train_loader)\nfeatures, labels = next(trainiter)\nfeatures.shape, labels.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataiter = iter(train_loader)\nimages, labels = dataiter.next()\nimages = images.numpy() # convert images to numpy for display\n\n# plot the images in the batch, along with the corresponding labels\nfig = plt.figure(figsize=(25, 4))\nfor idx in np.arange(15):                                             #Change the range according to your batch-size\n    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n    plt.imshow(np.transpose(images[idx], (1, 2, 0)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check if GPU available or not\ntrain_on_gpu = torch.cuda.is_available()\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.resnet152(pretrained = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for param in model.parameters():\n    param.requires_grad = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fc =  nn.Sequential(\n            nn.Linear(2048, 1024),\n            nn.ReLU(),\n            nn.BatchNorm1d(1024,eps=1e-05, momentum=0.1, affine=True),\n            nn.Dropout(0.35),\n            nn.Linear(1024, 67),\n#             nn.Linear(1024, 512),\n#             nn.ReLU(),\n#             nn.BatchNorm1d(512,eps=1e-05, momentum=0.1, affine=True),\n#             nn.Dropout(0.35),\n#             nn.Linear(512, 67),\n            nn.LogSoftmax(dim=1)\n            \n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for name, child in model.named_children():\n    if name in ['layer3','layer4','fc']:\n        print(name + ' is unfrozen')\n        for param in child.parameters():\n            param.requires_grad = True\n    else:\n        print(name + ' is frozen')\n        for param in child.parameters():\n            param.requires_grad = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0006, momentum=0.9, weight_decay=1e-5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncriterion = nn.CrossEntropyLoss()\n\n\n#optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0008, momentum=0.9)\nscheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if train_on_gpu:\n    model.cuda()\n    print(\"moved\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training the model and saving checkpoints of best performances. That is lower validation loss and higher accuracy\nepochs = 50\nvalid_loss_min = np.Inf\nimport time\nfor epoch in range(epochs):\n    \n    \n    start = time.time()\n    \n    scheduler.step()\n    model.train()\n    \n    train_loss = 0.0\n    valid_loss = 0.0\n    \n    for inputs, labels in train_loader:\n        \n        \n       \n        # Move input and label tensors to the default device\n        inputs, labels = inputs.cuda(), labels.cuda()\n        \n        optimizer.zero_grad()\n        \n        logps = model(inputs)\n#         _, preds = torch.max(logps, 1)\n        loss = criterion(logps, labels)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n        \n       \n    model.eval()\n    \n    with torch.no_grad():\n        accuracy = 0\n        for inputs, labels in valid_loader:\n            \n            inputs, labels = inputs.cuda(), labels.cuda()\n            logps = model.forward(inputs)\n            batch_loss = criterion(logps, labels)\n            valid_loss += batch_loss.item()\n            \n            # Calculate accuracy\n            ps = torch.exp(logps)\n            top_p, top_class = ps.topk(1, dim=1)\n            equals = top_class == labels.view(*top_class.shape)\n            accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n            \n    \n                    \n            \n            \n    # calculate average losses\n    train_loss = train_loss/len(train_loader)\n    valid_loss = valid_loss/len(valid_loader)\n    valid_accuracy = accuracy/len(valid_loader) \n      \n    # print training/validation statistics \n    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tValidation Accuracy: {:.6f}'.format(\n        epoch + 1, train_loss, valid_loss, valid_accuracy))\n            \n    \n    \n    if valid_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n        torch.save(model.state_dict(), 'model_resnet152_new.pt')\n        valid_loss_min = valid_loss        \n       \n    print(f\"Time per epoch: {(time.time() - start):.3f} seconds\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_state_dict(torch.load('model_resnet152_new.pt'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading sample_submission file to get the test image names\nsubmission = pd.read_csv('../input/sample_sub.csv')\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# iterate over test data to make predictions\npredictions = []\nfor data, target in test_loader:\n    # move tensors to GPU if CUDA is available\n    if train_on_gpu:\n        data, target = data.cuda(), target.cuda()\n    # forward pass: compute predicted outputs by passing inputs to the model\n    output = model(data)\n    _, pred = torch.max(output, 1)\n    for i in range(len(pred)):\n        predictions.append(int(pred[i]))\n        \n\nsubmission['Category'] = predictions       #Attaching predictions to submission file","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#saving submission file\nsubmission.to_csv('submission.csv', index=False, encoding='utf-8')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}